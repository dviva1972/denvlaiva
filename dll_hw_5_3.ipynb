{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dll_hw_5_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMH9wCBDCRHaG3o81Wb1F9z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dviva1972/denvlaiva/blob/master/dll_hw_5_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gnr5b_WvX7m"
      },
      "source": [
        "## DLL\n",
        "\n",
        "## Домашняя работа 5  |  RNN\n",
        "## Иванов Денис"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wwq0jG2ZuDrZ"
      },
      "source": [
        "## Задание 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HR0L_WYruLAs"
      },
      "source": [
        "Напишите алгоритм шифра цезаря для генерации выборки \n",
        "\n",
        "Создайте и обучите нейронную сеть (вход - зашифрованная фраза, выход - дешифрованная фраза)\n",
        "\n",
        "Проверьте качество модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6XgDyP_pjvP"
      },
      "source": [
        "1.1. Импорт библиотек"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Rq-LP3YuI2w"
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AObYk7DbovUs"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import sys\n",
        "from google.colab import drive "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9--cCzKKGzY"
      },
      "source": [
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLDPN3VXJsLJ"
      },
      "source": [
        "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkKa2S1so4jE",
        "outputId": "fb50618d-7183-4bc0-b830-1b4f52d21c72"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAnYff42v4TQ"
      },
      "source": [
        "1.2.  Алгоритм шифра Цезаря "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeaiOWUIuPc5"
      },
      "source": [
        "def Сaesar(string, num):\n",
        "    output = ''\n",
        "    for c in string:\n",
        "        if c.isalpha():\n",
        "            new_num = ord(c) + num\n",
        "            if new_num > ord('z'):\n",
        "                new_num -= 26\n",
        "            output += chr(new_num)\n",
        "        else:\n",
        "            output += c\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8K4bw1OBuVUG",
        "outputId": "12caf0a5-df3e-45d0-f6ac-2911adc87465"
      },
      "source": [
        "Сaesar('trew', 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'vtgy'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-Wm73XEwZVd"
      },
      "source": [
        "1.3. Исходные данные на базе изречений симпсонов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "zE4mhjfquf-m",
        "outputId": "ec2d769f-34fa-4bab-b08d-043e907f6ceb"
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/DLL/simpsons/data.csv').iloc[:,[-2]]\n",
        "df = df.dropna(subset=['normalized_text'])\n",
        "\n",
        "# установим произвольный сдвиг в составе шифра Цезаря до 10 символов\n",
        "# шифр индивидуален для каждой записи\n",
        "df['shift']   = [random.randint(1, 10) for i in range(len(df))]\n",
        "\n",
        "# исходная реплика\n",
        "df['text_in'] = [' '.join(re.findall('[\\w]+', i)) for i in df['normalized_text']]\n",
        "\n",
        "# зашифрованная реплика\n",
        "df['text_out']= df.loc[:, ['text_in', 'shift']].apply(\n",
        "                        lambda row: Сaesar(row['text_in'], row['shift']), axis=1)\n",
        "\n",
        "df = df.iloc[:,1:]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>shift</th>\n",
              "      <th>text_in</th>\n",
              "      <th>text_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>maggie look whats that</td>\n",
              "      <td>uiooqm twws epiba bpib</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>lee mur lee mur</td>\n",
              "      <td>tmm ucz tmm ucz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>zee boo zee boo</td>\n",
              "      <td>bgg dqq bgg dqq</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>im trying to teach maggie that nature doesnt e...</td>\n",
              "      <td>pt ayfpun av alhjo thnnpl aoha uhabyl kvlzua l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>its like an ox only it has a hump and a dewlap...</td>\n",
              "      <td>lwv olnh dq ra rqob lw kdv d kxps dqg d ghzods...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   shift  ...                                           text_out\n",
              "0      8  ...                             uiooqm twws epiba bpib\n",
              "1      8  ...                                    tmm ucz tmm ucz\n",
              "2      2  ...                                    bgg dqq bgg dqq\n",
              "3      7  ...  pt ayfpun av alhjo thnnpl aoha uhabyl kvlzua l...\n",
              "4      3  ...  lwv olnh dq ra rqob lw kdv d kxps dqg d ghzods...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt3pg8MDpWK4"
      },
      "source": [
        "Ограничим обучение первыми 50 символами каждой из реплик"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkL-dSXMPNNx"
      },
      "source": [
        "MAX_LEN       = 50\n",
        "col_name = ''.join(['text_in_', str(MAX_LEN), '_symb'])\n",
        "df[col_name] = [df.loc[i,'text_in'][:MAX_LEN] for i in df.index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYtAHKSn2vwv",
        "outputId": "408834d6-b302-4597-b538-bc1ead17ab03"
      },
      "source": [
        "df[col_name].value_counts().head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "no      52\n",
              "dad     37\n",
              "yes     30\n",
              "what    22\n",
              "bart    20\n",
              "hey     19\n",
              "yay     18\n",
              "yeah    17\n",
              "okay    17\n",
              "mom     16\n",
              "Name: text_in_50_symb, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COq-rEbWqDBh"
      },
      "source": [
        "По выборке чаще всего повторяются выражения состоящие из 3- 4 символов,  эта выборка реплик нерелевантна для задачи по генерации текста на 20+ символов. Исключим короткие реплики из наблюдения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewjerm-mbyco",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a4881b7c-e067-4978-d958-ef990f939b30"
      },
      "source": [
        "df['text_in_len'] =[len(df.loc[i,'text_in']) for i in df.index]\n",
        "df = df[df.text_in_len > 10]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>shift</th>\n",
              "      <th>text_in</th>\n",
              "      <th>text_out</th>\n",
              "      <th>text_in_50_symb</th>\n",
              "      <th>text_in_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>maggie look whats that</td>\n",
              "      <td>uiooqm twws epiba bpib</td>\n",
              "      <td>maggie look whats that</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>lee mur lee mur</td>\n",
              "      <td>tmm ucz tmm ucz</td>\n",
              "      <td>lee mur lee mur</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>zee boo zee boo</td>\n",
              "      <td>bgg dqq bgg dqq</td>\n",
              "      <td>zee boo zee boo</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>im trying to teach maggie that nature doesnt e...</td>\n",
              "      <td>pt ayfpun av alhjo thnnpl aoha uhabyl kvlzua l...</td>\n",
              "      <td>im trying to teach maggie that nature doesnt e...</td>\n",
              "      <td>122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>its like an ox only it has a hump and a dewlap...</td>\n",
              "      <td>lwv olnh dq ra rqob lw kdv d kxps dqg d ghzods...</td>\n",
              "      <td>its like an ox only it has a hump and a dewlap...</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   shift  ... text_in_len\n",
              "0      8  ...          22\n",
              "1      8  ...          15\n",
              "2      2  ...          15\n",
              "3      7  ...         122\n",
              "4      3  ...          80\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWnA1AkxqDlh"
      },
      "source": [
        "1.4. Импорт to Torch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQd6ZaqzavkE"
      },
      "source": [
        "train, test = train_test_split(df, test_size=0.2)\n",
        "train_text = [[c for c in ph] for ph in train['text_out'] if type(ph) is str]\n",
        "train_label= [[c for c in ph] for ph in train['text_in'] if type(ph) is str]\n",
        "test_text   = [[c for c in ph] for ph in test['text_out'] if type(ph) is str]\n",
        "test_label  = [[c for c in ph] for ph in test['text_in'] if type(ph) is str]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gsSpu3SOVsa"
      },
      "source": [
        "ABC           = ['none'] + [w for w in set('abcdefghijklmnopqrstuvwxyz ')]\n",
        "CHAR_TO_INDEX = {w: i for i, w in enumerate(ABC)}\n",
        "INDEX_TO_CHAR = {i: w for i, w in enumerate(ABC)}\n",
        "\n",
        "def convert_to_torch(text):\n",
        "    output = torch.zeros((len(text), MAX_LEN), dtype=int)\n",
        "    for i in range(len(text)):\n",
        "        for j, w in enumerate(text[i]):\n",
        "            if j >= MAX_LEN:\n",
        "                break\n",
        "            output[i, j] = CHAR_TO_INDEX.get(w, CHAR_TO_INDEX['none'])\n",
        "\n",
        "    return output\n",
        "\n",
        "X_train= convert_to_torch(train_text)\n",
        "Y_train= convert_to_torch(train_label)\n",
        "X_test = convert_to_torch(test_text)\n",
        "Y_test = convert_to_torch(test_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvfXfOuOqL73"
      },
      "source": [
        "1.5. Базовая архтектура сети"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm2UTy-eavqU"
      },
      "source": [
        "class RNN_Network(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RNN_Network, self).__init__()\n",
        "        self.embeddings = torch.nn.Embedding(len(ABC), 28)\n",
        "        self.rnn = torch.nn.RNN(28, 256, batch_first=True)\n",
        "        self.linear = torch.nn.Linear(256, 28)\n",
        "\n",
        "    def forward(self, sentences, state=None):\n",
        "        embds = self.embeddings(sentences)\n",
        "        out, new_state = self.rnn(embds, state)\n",
        "        result = self.linear(out)\n",
        "        return result, new_state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8zf6Spu8kxd"
      },
      "source": [
        "model = RNN_Network().to(dev)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
        "epochs    = 40\n",
        "loss_best = 10**10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WXIG5QqqT5u"
      },
      "source": [
        "1.6.  Обучение сети "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdSOS6x7WEFD",
        "outputId": "f2b4093f-0555-4233-ac5a-593b8bace235"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    train_loss = 0.\n",
        "    train_passed = 0\n",
        "    test_loss = 0\n",
        "    test_passed = 0\n",
        "\n",
        "    for i in range(int(len(X_train) / 100)):\n",
        "        X_batch = X_train[i * 100:(i + 1) * 100].to(dev)\n",
        "        Y_batch = Y_train[i * 100:(i + 1) * 100].flatten().to(dev)\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        answers, _ = model.forward(X_batch)\n",
        "        answers = answers.view(-1, len(ABC))\n",
        "        loss = criterion(answers, Y_batch).to(dev)\n",
        "\n",
        "        if loss < loss_best: \n",
        "            model_best = copy.copy(model)#.to(dev)\n",
        "            loss_best = loss#.to(dev)\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_passed += 1\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        answers, _ = model.forward(X_test.to(dev))\n",
        "        answers = answers.view(-1, len(ABC))\n",
        "        loss = criterion(answers, Y_test.flatten().to(dev))\n",
        "        test_loss += loss.item()\n",
        "        test_passed += 1\n",
        "\n",
        "    if epoch%1 == 0: \n",
        "        print(f\"Epoch {epoch}. Time: {time.time() - start:.3f}, Train loss: {train_loss / train_passed:.3f}, Test loss: {test_loss / test_passed:.6f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0. Time: 1.024, Train loss: 1.976, Test loss: 1.609095\n",
            "Epoch 1. Time: 0.852, Train loss: 1.450, Test loss: 1.321104\n",
            "Epoch 2. Time: 0.876, Train loss: 1.243, Test loss: 1.187204\n",
            "Epoch 3. Time: 0.847, Train loss: 1.153, Test loss: 1.129084\n",
            "Epoch 4. Time: 0.839, Train loss: 1.108, Test loss: 1.096524\n",
            "Epoch 5. Time: 0.844, Train loss: 1.079, Test loss: 1.072614\n",
            "Epoch 6. Time: 0.844, Train loss: 1.056, Test loss: 1.051958\n",
            "Epoch 7. Time: 0.844, Train loss: 1.035, Test loss: 1.031785\n",
            "Epoch 8. Time: 0.841, Train loss: 1.011, Test loss: 1.002696\n",
            "Epoch 9. Time: 0.842, Train loss: 0.972, Test loss: 0.953110\n",
            "Epoch 10. Time: 0.876, Train loss: 0.914, Test loss: 0.888802\n",
            "Epoch 11. Time: 0.842, Train loss: 0.853, Test loss: 0.851472\n",
            "Epoch 12. Time: 0.841, Train loss: 0.788, Test loss: 0.778426\n",
            "Epoch 13. Time: 0.839, Train loss: 0.748, Test loss: 0.736192\n",
            "Epoch 14. Time: 0.847, Train loss: 0.702, Test loss: 0.698213\n",
            "Epoch 15. Time: 0.846, Train loss: 0.658, Test loss: 0.659878\n",
            "Epoch 16. Time: 0.845, Train loss: 0.622, Test loss: 0.647367\n",
            "Epoch 17. Time: 0.850, Train loss: 0.594, Test loss: 0.595935\n",
            "Epoch 18. Time: 0.838, Train loss: 0.567, Test loss: 0.561214\n",
            "Epoch 19. Time: 0.849, Train loss: 0.529, Test loss: 0.530841\n",
            "Epoch 20. Time: 0.854, Train loss: 0.542, Test loss: 0.516042\n",
            "Epoch 21. Time: 0.841, Train loss: 0.475, Test loss: 0.488795\n",
            "Epoch 22. Time: 0.855, Train loss: 0.457, Test loss: 0.468315\n",
            "Epoch 23. Time: 0.841, Train loss: 0.435, Test loss: 0.467880\n",
            "Epoch 24. Time: 0.839, Train loss: 0.403, Test loss: 0.417065\n",
            "Epoch 25. Time: 0.842, Train loss: 0.438, Test loss: 0.478345\n",
            "Epoch 26. Time: 0.840, Train loss: 0.378, Test loss: 0.388395\n",
            "Epoch 27. Time: 0.843, Train loss: 0.340, Test loss: 0.372958\n",
            "Epoch 28. Time: 0.841, Train loss: 0.326, Test loss: 0.359073\n",
            "Epoch 29. Time: 0.848, Train loss: 0.306, Test loss: 0.363574\n",
            "Epoch 30. Time: 0.840, Train loss: 0.326, Test loss: 0.342821\n",
            "Epoch 31. Time: 0.849, Train loss: 0.282, Test loss: 0.318109\n",
            "Epoch 32. Time: 0.836, Train loss: 0.260, Test loss: 0.300435\n",
            "Epoch 33. Time: 0.858, Train loss: 0.244, Test loss: 0.289651\n",
            "Epoch 34. Time: 0.846, Train loss: 0.230, Test loss: 0.277487\n",
            "Epoch 35. Time: 0.837, Train loss: 0.216, Test loss: 0.265746\n",
            "Epoch 36. Time: 0.839, Train loss: 0.203, Test loss: 0.255790\n",
            "Epoch 37. Time: 0.836, Train loss: 0.191, Test loss: 0.250363\n",
            "Epoch 38. Time: 0.842, Train loss: 0.181, Test loss: 0.244177\n",
            "Epoch 39. Time: 0.833, Train loss: 0.171, Test loss: 0.239994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcwK4w2wINlq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ed94d30-454e-476c-ab80-15e7b1c498b0"
      },
      "source": [
        "loss_best"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1487, device='cuda:0', grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAxS23KAqIB-"
      },
      "source": [
        "1.7. Расшифровка текста / образцы"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kmey1qphJ1tk"
      },
      "source": [
        "ZZZ = convert_to_torch([[c for c in ph] for ph in df['text_out'] \n",
        "                                        if type(ph) is str])\n",
        "\n",
        "\n",
        "df['text_predict']= [''.join([INDEX_TO_CHAR[i.item()] for i \n",
        "                    in model_best(ZZZ.to(dev))[0][line].argmax(dim=1).detach()])\n",
        "                    for line in range(df.shape[0])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C05sSVnVKDZG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "outputId": "8d444c02-4fa5-4c9b-b195-7be5d216ab5e"
      },
      "source": [
        "df.iloc[170:185,[3,5]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_in_50_symb</th>\n",
              "      <th>text_predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>dad can i have some money to buy bart a birthd...</td>\n",
              "      <td>iad can i have some money to buy bart a birthd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>dad this is a hundred and ten dollars</td>\n",
              "      <td>dad this is a hundred and ten dollarsnonenonen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>quit it dad</td>\n",
              "      <td>wamt it dadnonenonenonenonenonenonenonenonenon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>i dreamed i was married to corey and we lived ...</td>\n",
              "      <td>i dreamed i was married to corey and we lived ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>is it sherri</td>\n",
              "      <td>is it sherrinonenonenonenonenonenonenonenoneno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208</th>\n",
              "      <td>how do you mean dad</td>\n",
              "      <td>iow do you mean dadnonenonenonenonenonenonenon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>how does that make him a hero</td>\n",
              "      <td>imw does that make him a herononenonenonenonen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>bart simpson the thought of a boy trapped in a...</td>\n",
              "      <td>iart simpson the thought of a boy trapped in a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>the police will catch you sooner or later</td>\n",
              "      <td>whe police will catch you sooner or laternonen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>maybe not but i bet youre stupid enough to hav...</td>\n",
              "      <td>iayde oot but i bet youre stupid enough to hav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>hey stop that</td>\n",
              "      <td>iey stop thatnonenonenonenonenonenonenonenonen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216</th>\n",
              "      <td>whats going on</td>\n",
              "      <td>whats going onnonenonenonenonenonenonenonenone...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>i dont know the dolphins</td>\n",
              "      <td>i dont lnow the dolpginsnonenonenonenonenoneno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>look dad i made a modest studio apartment for ...</td>\n",
              "      <td>mook dad i made a modest studio apartment for ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>daaaaad youre not listening to me</td>\n",
              "      <td>dabbbbd youre not listening to menonenonenonen...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       text_in_50_symb                                       text_predict\n",
              "203  dad can i have some money to buy bart a birthd...  iad can i have some money to buy bart a birthd...\n",
              "204              dad this is a hundred and ten dollars  dad this is a hundred and ten dollarsnonenonen...\n",
              "205                                        quit it dad  wamt it dadnonenonenonenonenonenonenonenonenon...\n",
              "206  i dreamed i was married to corey and we lived ...  i dreamed i was married to corey and we lived ...\n",
              "207                                       is it sherri  is it sherrinonenonenonenonenonenonenonenoneno...\n",
              "208                                how do you mean dad  iow do you mean dadnonenonenonenonenonenonenon...\n",
              "209                      how does that make him a hero  imw does that make him a herononenonenonenonen...\n",
              "212  bart simpson the thought of a boy trapped in a...  iart simpson the thought of a boy trapped in a...\n",
              "213          the police will catch you sooner or later  whe police will catch you sooner or laternonen...\n",
              "214  maybe not but i bet youre stupid enough to hav...  iayde oot but i bet youre stupid enough to hav...\n",
              "215                                      hey stop that  iey stop thatnonenonenonenonenonenonenonenonen...\n",
              "216                                     whats going on  whats going onnonenonenonenonenonenonenonenone...\n",
              "217                           i dont know the dolphins  i dont lnow the dolpginsnonenonenonenonenoneno...\n",
              "218  look dad i made a modest studio apartment for ...  mook dad i made a modest studio apartment for ...\n",
              "219                  daaaaad youre not listening to me  dabbbbd youre not listening to menonenonenonen..."
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU5xOobu1nt3"
      },
      "source": [
        "###Задание 2.\n",
        "\n",
        "Построить RNN-ячейку и применить ее\n",
        " для генерации текста с выражениями героев сериала “Симпсоны”"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_sO7MYQraDZ"
      },
      "source": [
        "X = convert_to_torch([[c for c in ph]  for ph in df['text_in'].tolist() \n",
        "                                        if type(ph) is str])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwuCu3Pweaqj"
      },
      "source": [
        "class Network(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "        self.embed = torch.nn.Embedding(len(CHAR_TO_INDEX), 28)\n",
        "        self.rnn = torch.nn.RNN(28, 812, batch_first=True)\n",
        "        self.linear = torch.nn.Linear(812, len(INDEX_TO_CHAR))\n",
        "        \n",
        "    def forward(self, sentences, state=None):\n",
        "        embed = self.embed(sentences)\n",
        "        o, s = self.rnn(embed)\n",
        "        out = self.linear(o)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn8W0jk5SOEC"
      },
      "source": [
        "def generate_sentence(txt_list):\n",
        "\n",
        "    sentence =  [c for c in txt_list]\n",
        "    x = torch.zeros((1, len(sentence)), dtype=int).to(dev)\n",
        "    \n",
        "    for j,w in enumerate(sentence):\n",
        "        if j >= MAX_S_LEN:\n",
        "            break\n",
        "        x[0, j] = CHAR_TO_INDEX.get(w, CHAR_TO_INDEX['none'])\n",
        "        \n",
        "    for i in range(MAX_LEN):\n",
        "        o = model(x)\n",
        "        w = torch.argmax(o[-1, -1, :], keepdim=True)\n",
        "        x = torch.cat([x, w.unsqueeze(0).unsqueeze(1)], axis=1)\n",
        "        ww = INDEX_TO_CHAR[w.item()]\n",
        "        if ww == 'none':\n",
        "            break\n",
        "\n",
        "        sentence.append(ww)\n",
        "\n",
        "    return ''.join(sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IU6zALb5SOED"
      },
      "source": [
        "model     = Network().to(dev)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=.0001)\n",
        "MAX_S_LEN = 100\n",
        "phrase = 'youre a great mom '"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BiaUWekSOED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ed81038-41ac-4d8a-8026-e0926ec31cb8"
      },
      "source": [
        "for ep in range(200):\n",
        "    start = time.time()\n",
        "    train_loss = 0.\n",
        "    train_passed = 0\n",
        "\n",
        "    for i in range(int(len(X) / 100)):\n",
        "        batch = X[i * 100:(i + 1) * 100] \n",
        "        X_batch = batch[:, :-1].to(dev)\n",
        "        Y_batch = batch[:, 1:].flatten().to(dev) \n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        answers = model(X_batch)\n",
        "        answers = answers.view(-1, len(INDEX_TO_CHAR))\n",
        "        loss = criterion(answers, Y_batch).to(dev)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_passed += 1     \n",
        "\n",
        "    if ep%10 == 0: \n",
        "        print(\"\\nEpoch {}. Time: {:.3f}, Train loss: {:.3f}\".format(ep, time.time() - start, train_loss / train_passed))\n",
        "        s = generate_sentence(phrase)\n",
        "        print(s)\n",
        "    else:\n",
        "        print(f\"\\rEpoch {ep}, loss: {train_loss / train_passed:.3f}\", end='') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 0. Time: 2.424, Train loss: 2.301\n",
            "youre a great mom to to to to to to to to to to to to to to to to to\n",
            "Epoch 9, loss: 1.592\n",
            "Epoch 10. Time: 2.389, Train loss: 1.569\n",
            "youre a great mom the some the some the some the some the some the s\n",
            "Epoch 19, loss: 1.403\n",
            "Epoch 20. Time: 2.413, Train loss: 1.389\n",
            "youre a great mom i sould the some the some of the something the som\n",
            "Epoch 29, loss: 1.281\n",
            "Epoch 30. Time: 2.399, Train loss: 1.271\n",
            "youre a great mom i sad the something the something the something th\n",
            "Epoch 39, loss: 1.194\n",
            "Epoch 40. Time: 2.391, Train loss: 1.187\n",
            "youre a great mom i sad the story with the bart what are you so much\n",
            "Epoch 49, loss: 1.130\n",
            "Epoch 50. Time: 2.405, Train loss: 1.124\n",
            "youre a great mom i said the best thing is a some thing is a some th\n",
            "Epoch 59, loss: 1.079\n",
            "Epoch 60. Time: 2.394, Train loss: 1.074\n",
            "youre a great mom i said the bast thing is a some thing is a some to\n",
            "Epoch 69, loss: 1.035\n",
            "Epoch 70. Time: 2.389, Train loss: 1.031\n",
            "youre a great mom i said the bast thing is a song is a could be a li\n",
            "Epoch 79, loss: 0.996\n",
            "Epoch 80. Time: 2.416, Train loss: 0.992\n",
            "youre a great mom i have a better will be the start to the baby said\n",
            "Epoch 89, loss: 0.960\n",
            "Epoch 90. Time: 2.401, Train loss: 0.956\n",
            "youre a great mom i have a but he want to get the same this to the b\n",
            "Epoch 99, loss: 0.926\n",
            "Epoch 100. Time: 2.405, Train loss: 0.922\n",
            "youre a great mom i have a buddhist\n",
            "Epoch 109, loss: 0.894\n",
            "Epoch 110. Time: 2.393, Train loss: 0.891\n",
            "youre a great mom i dont know what hopeone is the only one of these \n",
            "Epoch 119, loss: 0.864\n",
            "Epoch 120. Time: 2.396, Train loss: 0.861\n",
            "youre a great mom i have a real to be a bart\n",
            "Epoch 129, loss: 0.836\n",
            "Epoch 130. Time: 2.406, Train loss: 0.834\n",
            "youre a great mom i dont know what hopses in the wind with the first\n",
            "Epoch 139, loss: 0.812\n",
            "Epoch 140. Time: 2.383, Train loss: 0.809\n",
            "youre a great mom i dont know what hopro and i want to get to the on\n",
            "Epoch 149, loss: 0.789\n",
            "Epoch 150. Time: 2.386, Train loss: 0.787\n",
            "youre a great mom in the way out of this\n",
            "Epoch 159, loss: 0.767\n",
            "Epoch 160. Time: 2.391, Train loss: 0.764\n",
            "youre a great mom i dont know what how could you know that the back \n",
            "Epoch 169, loss: 0.736\n",
            "Epoch 170. Time: 2.412, Train loss: 0.733\n",
            "youre a great mom i dont know what how could you know that the back \n",
            "Epoch 179, loss: 0.710\n",
            "Epoch 180. Time: 2.419, Train loss: 0.709\n",
            "youre a great mom i dont know what the hell his boby with the truth \n",
            "Epoch 189, loss: 0.696\n",
            "Epoch 190. Time: 2.402, Train loss: 0.692\n",
            "youre a great mom i have a brother bart years had the boy book the s\n",
            "Epoch 199, loss: 0.661"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvCT8KKSsqBC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}